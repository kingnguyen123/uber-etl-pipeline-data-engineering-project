# uber-etl-pipeline-data-engineering-project


## Introduction
>This project focuses on performing data analytics on Uber trip data using various tools and technologies on Amazon Web Services(AWS). The project demonstrates the use of S3 Bucket, Python, EC2, Apache Airflow, Redshift, and Power BI for an end-to-end data engineering and analytics workflow. 

## Architecture
![Architecture diagramming](https://github.com/kingnguyen123/uber-etl-pipeline-data-engineering-project/blob/main/Architecture.pdf)

## Technology Used
>Programming Language - Python
>Amazon Web Services
>s3 bucket
>EC2
>Redshift
>Power BI
>Airflow

## Dataset Used
>TLC Trip Record Data Yellow and green taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.

>Website - https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
>Data Dictionary - https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf

## Data Model
![Data Model](https://raw.githubusercontent.com/kingnguyen123/uber-etl-pipeline-data-engineering-project/main/data_model.jpeg)

## Architecture

[![Architecture Diagram](https://github.com/kingnguyen123/uber-etl-pipeline-data-engineering-project/blob/main/Architecture.png)](https://github.com/kingnguyen123/uber-etl-pipeline-data-engineering-project/blob/main/Architecture.pdf)





